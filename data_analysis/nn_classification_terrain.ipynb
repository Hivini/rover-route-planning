{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 17:13:22.663325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5]), array([1369,  197,  192,   96,  361,  246]))\n",
      "1722\n",
      "1722\n",
      "369\n",
      "369\n",
      "370\n",
      "370\n",
      "6\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "\n",
    "terrains = ('Plano', 'Bordes',\n",
    "            'Cr치ter peque침o', 'Cr치ter profundo', 'Colina', 'Monta침a')\n",
    "\n",
    "x = np.load(f'terrain_data.npy')\n",
    "y = np.load(f'terrain_data_labels.npy')\n",
    "y = y-1\n",
    "\n",
    "x, y = shuffle(x, y)\n",
    "\n",
    "x_train, x_val, x_test = np.split(\n",
    "    np.array(x), [int(len(x)*0.7), int(len(x)*0.85)])\n",
    "y_train, y_val, y_test = np.split(\n",
    "    np.array(y), [int(len(y)*0.7), int(len(y)*0.85)])\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "n_clases = len(terrains)\n",
    "n_features = 17\n",
    "\n",
    "print(np.unique(y, return_counts=True))\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_val))\n",
    "print(len(y_val))\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "print(n_clases)\n",
    "print(n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 17:13:25.574568: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-11 17:13:25.588039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-11 17:13:26.052305: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:26.052386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.215GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-11-11 17:13:26.052514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-11 17:13:26.057561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-11 17:13:26.057780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-11-11 17:13:26.060871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-11 17:13:26.061894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-11 17:13:26.065558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-11 17:13:26.067805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-11 17:13:26.075367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-11 17:13:26.076374: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:26.077252: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:26.077296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-11-11 17:13:26.079014: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-11 17:13:26.083250: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:26.083326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.215GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-11-11 17:13:26.083443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-11 17:13:26.083533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-11 17:13:26.083590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-11-11 17:13:26.083621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-11 17:13:26.083650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-11 17:13:26.083679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-11 17:13:26.083710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-11 17:13:26.083740: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-11 17:13:26.084832: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:26.086134: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:26.086196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-11-11 17:13:26.086352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-11 17:13:27.625716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-11 17:13:27.625782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-11-11 17:13:27.625795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-11-11 17:13:27.627464: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:27.627545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1489] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-11-11 17:13:27.628787: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:27.629856: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-11 17:13:27.629980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6575 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-11-11 17:13:27.630537: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras import backend\n",
    "\n",
    "# We want to make sure we start from the start when training our model everytime we run it.\n",
    "backend.clear_session()\n",
    "\n",
    "\n",
    "# Define MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=n_features, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(n_clases, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               4608      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 23,334\n",
      "Trainable params: 23,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hivini/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass classes=[0 1 2 3 4 5], y=[0 0 0 ... 1 0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "2021-11-11 17:13:28.782945: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-11 17:13:28.783559: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2208005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 17:13:29.602934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 5s 12ms/step - loss: 9.8535 - accuracy: 0.2441 - val_loss: 3.3593 - val_accuracy: 0.2168\n",
      "Epoch 2/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 5.5007 - accuracy: 0.1828 - val_loss: 2.2408 - val_accuracy: 0.4336\n",
      "Epoch 3/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 2.2052 - accuracy: 0.4113 - val_loss: 1.8739 - val_accuracy: 0.4065\n",
      "Epoch 4/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 2.4707 - accuracy: 0.4953 - val_loss: 1.6553 - val_accuracy: 0.3930\n",
      "Epoch 5/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.6781 - accuracy: 0.4050 - val_loss: 1.6332 - val_accuracy: 0.3442\n",
      "Epoch 6/150\n",
      "287/287 [==============================] - 3s 12ms/step - loss: 1.5401 - accuracy: 0.4151 - val_loss: 1.5777 - val_accuracy: 0.4255\n",
      "Epoch 7/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.5153 - accuracy: 0.4290 - val_loss: 1.8436 - val_accuracy: 0.3902\n",
      "Epoch 8/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.8273 - accuracy: 0.4438 - val_loss: 1.5929 - val_accuracy: 0.4336\n",
      "Epoch 9/150\n",
      "287/287 [==============================] - 2s 8ms/step - loss: 1.6252 - accuracy: 0.3900 - val_loss: 1.5270 - val_accuracy: 0.5014\n",
      "Epoch 10/150\n",
      "287/287 [==============================] - 2s 8ms/step - loss: 1.5411 - accuracy: 0.5133 - val_loss: 1.5365 - val_accuracy: 0.4959\n",
      "Epoch 11/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5867 - accuracy: 0.4617 - val_loss: 1.4951 - val_accuracy: 0.5176\n",
      "Epoch 12/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5274 - accuracy: 0.5281 - val_loss: 1.7117 - val_accuracy: 0.5176\n",
      "Epoch 13/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.6417 - accuracy: 0.5439 - val_loss: 1.5526 - val_accuracy: 0.5176\n",
      "Epoch 14/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.4967 - accuracy: 0.5504 - val_loss: 1.4950 - val_accuracy: 0.5203\n",
      "Epoch 15/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.5032 - accuracy: 0.5442 - val_loss: 1.5111 - val_accuracy: 0.5149\n",
      "Epoch 16/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5015 - accuracy: 0.5339 - val_loss: 1.5196 - val_accuracy: 0.3550\n",
      "Epoch 17/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5223 - accuracy: 0.4214 - val_loss: 1.3507 - val_accuracy: 0.4580\n",
      "Epoch 18/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5042 - accuracy: 0.4324 - val_loss: 1.5505 - val_accuracy: 0.3306\n",
      "Epoch 19/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.4734 - accuracy: 0.4202 - val_loss: 1.4465 - val_accuracy: 0.4011\n",
      "Epoch 20/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5557 - accuracy: 0.4409 - val_loss: 1.4515 - val_accuracy: 0.4201\n",
      "Epoch 21/150\n",
      "287/287 [==============================] - 2s 9ms/step - loss: 1.4334 - accuracy: 0.4342 - val_loss: 1.4861 - val_accuracy: 0.3794\n",
      "Epoch 22/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.4655 - accuracy: 0.3851 - val_loss: 1.4231 - val_accuracy: 0.4065\n",
      "Epoch 23/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.4998 - accuracy: 0.4575 - val_loss: 1.3679 - val_accuracy: 0.4580\n",
      "Epoch 24/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.6264 - accuracy: 0.4406 - val_loss: 1.4722 - val_accuracy: 0.4472\n",
      "Epoch 25/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.7141 - accuracy: 0.4093 - val_loss: 1.2939 - val_accuracy: 0.4959\n",
      "Epoch 26/150\n",
      "287/287 [==============================] - 2s 8ms/step - loss: 1.4814 - accuracy: 0.4988 - val_loss: 1.5514 - val_accuracy: 0.3496\n",
      "Epoch 27/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.4373 - accuracy: 0.4501 - val_loss: 1.2279 - val_accuracy: 0.5366\n",
      "Epoch 28/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.3754 - accuracy: 0.5013 - val_loss: 1.5744 - val_accuracy: 0.2629\n",
      "Epoch 29/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.5089 - accuracy: 0.3554 - val_loss: 1.3681 - val_accuracy: 0.4472\n",
      "Epoch 30/150\n",
      "287/287 [==============================] - 2s 9ms/step - loss: 1.3664 - accuracy: 0.4590 - val_loss: 1.4623 - val_accuracy: 0.4255\n",
      "Epoch 31/150\n",
      "287/287 [==============================] - 2s 9ms/step - loss: 1.4174 - accuracy: 0.4464 - val_loss: 1.3341 - val_accuracy: 0.4851\n",
      "Epoch 32/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.3452 - accuracy: 0.5077 - val_loss: 1.3365 - val_accuracy: 0.5068\n",
      "Epoch 33/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.3371 - accuracy: 0.5141 - val_loss: 1.3216 - val_accuracy: 0.4580\n",
      "Epoch 34/150\n",
      "287/287 [==============================] - 2s 8ms/step - loss: 1.3018 - accuracy: 0.5120 - val_loss: 1.3889 - val_accuracy: 0.3848\n",
      "Epoch 35/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.3530 - accuracy: 0.4990 - val_loss: 1.5438 - val_accuracy: 0.2900\n",
      "Epoch 36/150\n",
      "287/287 [==============================] - 2s 8ms/step - loss: 1.3427 - accuracy: 0.3450 - val_loss: 1.3186 - val_accuracy: 0.4634\n",
      "Epoch 37/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2973 - accuracy: 0.4592 - val_loss: 1.6031 - val_accuracy: 0.3306\n",
      "Epoch 38/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5107 - accuracy: 0.3545 - val_loss: 1.4071 - val_accuracy: 0.4309\n",
      "Epoch 39/150\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.4772 - accuracy: 0.4715 - val_loss: 1.2142 - val_accuracy: 0.5203\n",
      "Epoch 40/150\n",
      "287/287 [==============================] - 4s 12ms/step - loss: 1.3400 - accuracy: 0.5223 - val_loss: 1.2110 - val_accuracy: 0.5203\n",
      "Epoch 41/150\n",
      "287/287 [==============================] - 3s 11ms/step - loss: 1.3355 - accuracy: 0.5409 - val_loss: 1.2851 - val_accuracy: 0.4688\n",
      "Epoch 42/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2873 - accuracy: 0.4645 - val_loss: 1.3613 - val_accuracy: 0.5041\n",
      "Epoch 43/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.5390 - accuracy: 0.5138 - val_loss: 1.3436 - val_accuracy: 0.4444\n",
      "Epoch 44/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2346 - accuracy: 0.5128 - val_loss: 1.3366 - val_accuracy: 0.4526\n",
      "Epoch 45/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.3114 - accuracy: 0.4824 - val_loss: 1.4961 - val_accuracy: 0.3794\n",
      "Epoch 46/150\n",
      "287/287 [==============================] - 2s 9ms/step - loss: 1.3309 - accuracy: 0.4301 - val_loss: 1.4652 - val_accuracy: 0.3604\n",
      "Epoch 47/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2711 - accuracy: 0.4973 - val_loss: 1.5349 - val_accuracy: 0.4255\n",
      "Epoch 48/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2497 - accuracy: 0.5046 - val_loss: 1.3342 - val_accuracy: 0.4472\n",
      "Epoch 49/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2402 - accuracy: 0.5049 - val_loss: 1.2220 - val_accuracy: 0.5149\n",
      "Epoch 50/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2138 - accuracy: 0.4997 - val_loss: 1.3913 - val_accuracy: 0.4228\n",
      "Epoch 51/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2674 - accuracy: 0.4762 - val_loss: 1.3921 - val_accuracy: 0.4173\n",
      "Epoch 52/150\n",
      "287/287 [==============================] - 2s 9ms/step - loss: 1.2780 - accuracy: 0.4767 - val_loss: 1.3591 - val_accuracy: 0.4634\n",
      "Epoch 53/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2972 - accuracy: 0.4458 - val_loss: 1.3551 - val_accuracy: 0.4309\n",
      "Epoch 54/150\n",
      "287/287 [==============================] - 2s 9ms/step - loss: 1.2117 - accuracy: 0.4897 - val_loss: 1.2843 - val_accuracy: 0.4878\n",
      "Epoch 55/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1904 - accuracy: 0.5451 - val_loss: 1.2248 - val_accuracy: 0.4580\n",
      "Epoch 56/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2459 - accuracy: 0.4635 - val_loss: 1.2960 - val_accuracy: 0.4932\n",
      "Epoch 57/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2977 - accuracy: 0.5084 - val_loss: 1.7247 - val_accuracy: 0.2249\n",
      "Epoch 58/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.3389 - accuracy: 0.2931 - val_loss: 1.4546 - val_accuracy: 0.3713\n",
      "Epoch 59/150\n",
      "287/287 [==============================] - 2s 9ms/step - loss: 1.2070 - accuracy: 0.4225 - val_loss: 1.3210 - val_accuracy: 0.4499\n",
      "Epoch 60/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1955 - accuracy: 0.4773 - val_loss: 1.5428 - val_accuracy: 0.3686\n",
      "Epoch 61/150\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2495 - accuracy: 0.4353 - val_loss: 1.5022 - val_accuracy: 0.3550\n",
      "Epoch 62/150\n",
      "164/287 [================>.............] - ETA: 1s - loss: 1.3714 - accuracy: 0.4033"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7059/746344219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                   y)\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit(x_train, y_train, validation_data=(x_val, y_val), class_weight=(\n\u001b[0m\u001b[1;32m      9\u001b[0m     dict(zip(np.unique(y), class_weights))), epochs=150, batch_size=6)\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "es = EarlyStopping(monitor='val_acc', mode='min', verbose=1, patience=10)\n",
    "# Fit model\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(y),\n",
    "                                                  y)\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), class_weight=(\n",
    "    dict(zip(np.unique(y), class_weights))), epochs=150, batch_size=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "# bo is for blue dot.\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "# b is for solid blue line\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "732f00c41ec6febe1195a3ec4989d3211f40efb04fd77f25a6f0f8bfd6feb066"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
